{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1600x1062 at 0x1289C87D0>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DinoV2\n",
    "\n",
    "* Load selected `DinoV2` model from PyTorch model hub\n",
    "* Run inference and extract features\n",
    "* Use PCA to visualise results (not necessary for our use-case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = vgg19()\n",
    "resnet_model = resnet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DinoV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /Users/michal/.cache/torch/hub/main.zip\n",
      "/Users/michal/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/Users/michal/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/Users/michal/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\" to /Users/michal/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth\n",
      "100%|██████████| 1.13G/1.13G [02:18<00:00, 8.82MB/s]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('../data/test-elephant.png')\n",
    "\n",
    "dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(520),\n",
    "    T.CenterCrop(518),           \n",
    "    T.ToTensor(),               \n",
    "    T.Normalize(mean=0.5, std=0.2)\n",
    "])\n",
    "\n",
    "patch_size = dinov2.patch_size # patchsize=14\n",
    "\n",
    "patch_h  = 520//patch_size\n",
    "patch_w  = 520//patch_size\n",
    "\n",
    "feat_dim = 1024\n",
    "\n",
    "img = transform(img)\n",
    "\n",
    "with torch.no_grad():\n",
    "    features_dict = dinov2.forward_features(img.unsqueeze(0))\n",
    "    features = features_dict['x_norm_patchtokens']\n",
    "\n",
    "total_features = features.reshape(1 * patch_h * patch_w, feat_dim)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(total_features)\n",
    "pca_features = pca.transform(total_features)\n",
    "\n",
    "pca_features[:, 0] = (pca_features[:, 0] - pca_features[:, 0].min()) / \\\n",
    "                     (pca_features[:, 0].max() - pca_features[:, 0].min())\n",
    "plt.imshow(pca_features[:, 0].reshape(patch_h, patch_w))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FAISS\n",
    "\n",
    "* Create flat index (choose appropriate index size)\n",
    "* Add single element to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(features.shape[1] * features.shape[2])\n",
    "index.add(features.reshape((features.shape[0], features.shape[1] * features.shape[2])).numpy())\n",
    "index.ntotal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
