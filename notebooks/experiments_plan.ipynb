{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksperymenty\n",
    "\n",
    "**Modele**\n",
    "- resnet50\n",
    "- vgg16\n",
    "\n",
    "**Zbiory danych**\n",
    "- CIFAR100\n",
    "- SVHN\n",
    "\n",
    "**Metody**\n",
    "- Random\n",
    "- KMeans\n",
    "- KMeansPurity\n",
    "- KMeansDino\n",
    "- KMeansDinoPurity\n",
    "\n",
    "**Ustawienia**\n",
    "- ratio = (0.1, 1, 10)\n",
    "- epochs = 10\n",
    "- batch_size = 512\n",
    "- clip = 5.0\n",
    "- num_clusters = 10\n",
    "- eqsize = True\n",
    "- min_purity = 0.1 (SVHN), 0.01 (CIFAR100)\n",
    "\n",
    "**Nazewnictwo przebiegów**\n",
    "W nawiasach kwadratowych podano wartość do wyboru (\"jeden z ...\") w nawiasch klamrowych wartości opcjonalne.\n",
    "ID służy do rozróżniania eksperymentów w tej samej konfiguracji\n",
    "\n",
    "- [r50,vgg13],ep:10,bs:512,clip:5.0,{nc:20},{eqsize},{mp:[0.1,0.01]},ID:[1,2,3,..]\n",
    "- przykład: r50,ep:10,bs:512,clip:5.0,ID:1\n",
    "- przykład: r50,ep:10,bs:512,clip:50,nc:20,eqsize,mp:0.1,ID:1\n",
    "\n",
    "**Uwagi**\n",
    "- Przy każdym eksperymencie nowy model (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from kiss.models import vgg16_kiss\n",
    "from kiss.experiment import Experiment\n",
    "from kiss.sampler import RandomSampler, KMeansSampler, KMeansPuritySampler, KMeansPurity2Sampler, KMeansDinoSampler, KMeansPurityDinoSampler\n",
    "from kiss.utils.configs import CONFIGS\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "dataset_cifar100_tr = torchvision.datasets.CIFAR100(root='../data/cifar100', train=True, download=True, transform=transform)\n",
    "dataset_cifar100_te = torchvision.datasets.CIFAR100(root='../data/cifar100', train=False, download=True, transform=transform)\n",
    "\n",
    "dataset_svhn_tr = torchvision.datasets.SVHN(root='../data/svhn', split='train', download=True, transform=transform)\n",
    "dataset_svhn_te = torchvision.datasets.SVHN(root='../data/svhn', split='test', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 5\n",
    "RATIO = (0.1, 0.3, 3)\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 512\n",
    "CLIP = 5.0\n",
    "NUM_CLUSTERS = 10\n",
    "EQSIZE = True\n",
    "\n",
    "# 5 - poprawna walidacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mRunning experiment ResNet!CIFAR100!RandomSampler\n",
      "\u001b[0m\u001b[1m\u001b[95mRunning run r50,ep:10,bs:512,clip:5.0,ID:5/1\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 8/8 [00:04<00:00,  1.77 batch/s, loss=5.1547]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.40 batch/s, loss=4.6781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid loss improved. Current accuracy is 0.97%. Saving checkpoint...\n",
      "\u001b[0m\u001b[1m\u001b[36mBest valid accuracy improved. Current accuracy is 0.97%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 8/8 [00:03<00:00,  2.20 batch/s, loss=4.6894]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.43 batch/s, loss=4.8054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved. Current accuracy is 1.00%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 8/8 [00:03<00:00,  2.23 batch/s, loss=4.1967]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.44 batch/s, loss=4.8718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved. Current accuracy is 1.24%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 8/8 [00:03<00:00,  2.21 batch/s, loss=3.7937]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.49 batch/s, loss=4.9795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved. Current accuracy is 2.18%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 8/8 [00:03<00:00,  2.21 batch/s, loss=3.2669]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.54 batch/s, loss=4.8974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved. Current accuracy is 2.98%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 8/8 [00:03<00:00,  2.20 batch/s, loss=2.5772]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.59 batch/s, loss=4.5371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid loss improved. Current accuracy is 5.32%. Saving checkpoint...\n",
      "\u001b[0m\u001b[1m\u001b[36mBest valid accuracy improved. Current accuracy is 5.32%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 8/8 [00:03<00:00,  2.21 batch/s, loss=1.7841]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.57 batch/s, loss=4.7266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved. Current accuracy is 7.43%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 8/8 [00:03<00:00,  2.17 batch/s, loss=1.1963]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.37 batch/s, loss=5.0793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved. Current accuracy is 8.44%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 8/8 [00:03<00:00,  2.23 batch/s, loss=0.8468]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.42 batch/s, loss=5.8110]\n",
      "Epoch 10/10: 100%|██████████| 8/8 [00:03<00:00,  2.19 batch/s, loss=0.6313]\n",
      "Validating: 100%|██████████| 20/20 [00:03<00:00,  5.38 batch/s, loss=6.0760]\n",
      "Testing: 100%|██████████| 20/20 [00:03<00:00,  5.40 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95mRunning run r50,ep:10,bs:512,clip:5.0,ID:5/2\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 16/16 [00:07<00:00,  2.14 batch/s, loss=5.0323]\n",
      "Validating:  80%|████████  | 16/20 [00:03<00:00,  4.91 batch/s, loss=4.7304]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdevice(CONFIGS\u001b[38;5;241m.\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m     42\u001b[0m experiment \u001b[38;5;241m=\u001b[39m Experiment(\n\u001b[1;32m     43\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m     44\u001b[0m     dataset_tr \u001b[38;5;241m=\u001b[39m dataset_tr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     save_clusters\u001b[38;5;241m=\u001b[39mSAVE_CLUSTERS,\n\u001b[1;32m     56\u001b[0m )\n\u001b[0;32m---> 57\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../experiments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRUN_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHub/KISS/src/kiss/experiment/base.py:89\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self, savepath, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_savepath_)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test()\n",
      "File \u001b[0;32m~/GitHub/KISS/src/kiss/experiment/base.py:115\u001b[0m, in \u001b[0;36mExperiment._train\u001b[0;34m(self, ratio)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):            \n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__train_epoch(train_loader, epoch, criterion, optimizer)\n\u001b[0;32m--> 115\u001b[0m     best_valid_loss, best_valid_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__valid_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_valid_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_valid_acc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_savepath_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratio.txt\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    118\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mratio\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/GitHub/KISS/src/kiss/experiment/base.py:165\u001b[0m, in \u001b[0;36mExperiment.__valid_epoch\u001b[0;34m(self, valid_loader, criterion, best_valid_loss, best_valid_acc)\u001b[0m\n\u001b[1;32m    163\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    164\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    168\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for model_fun in [resnet50]:\n",
    "    for dataset_tr, dataset_te in zip([dataset_cifar100_tr, dataset_svhn_tr], [dataset_cifar100_te, dataset_svhn_te]):\n",
    "        for sampler_cls in [KMeansDinoSampler]:\n",
    "\n",
    "            if model_fun.__name__ == 'resnet50':\n",
    "                MODEL_NAME = 'r50'\n",
    "            if model_fun.__name__ == 'vgg16':\n",
    "                MODEL_NAME = 'vgg16'\n",
    "            if model_fun.__name__ == 'vgg16_kiss':\n",
    "                MODEL_NAME = 'vgg16_kiss'\n",
    "\n",
    "            RUN_NAME = f\"{MODEL_NAME},ep:{EPOCHS},bs:{BATCH_SIZE},clip:{CLIP}\"\n",
    "\n",
    "            if dataset_tr.__class__.__name__ == 'SVHN':\n",
    "                NUM_CLASSES = 10\n",
    "                MIN_PURITY = 0.1\n",
    "            if dataset_tr.__class__.__name__ == 'CIFAR100':\n",
    "                NUM_CLASSES = 100\n",
    "                MIN_PURITY = 0.01\n",
    "\n",
    "            if 'KMeans' in sampler_cls.__name__:\n",
    "                RUN_NAME += f\",nc:{NUM_CLUSTERS}\"\n",
    "\n",
    "            if 'KMeans' in sampler_cls.__name__ and EQSIZE:\n",
    "                RUN_NAME += \",eqsize\"\n",
    "\n",
    "            if 'KMeansPurity' in sampler_cls.__name__:\n",
    "                RUN_NAME += f\",mp:{MIN_PURITY}\"\n",
    "\n",
    "            SAVE_CLUSTERS = LOAD_CLUSTERS = f\"../checkpoints/{sampler_cls.__name__},{dataset_tr.__class__.__name__},nc:{NUM_CLUSTERS}\"\n",
    "            \n",
    "            if not os.path.exists(LOAD_CLUSTERS):\n",
    "                LOAD_CLUSTERS = None\n",
    "            \n",
    "            RUN_NAME += f',ID:{ID}'\n",
    "\n",
    "            model = model_fun(num_classes=NUM_CLASSES)\n",
    "            model.to(torch.device(CONFIGS.torch.device))\n",
    "\n",
    "            experiment = Experiment(\n",
    "                model = model,\n",
    "                dataset_tr = dataset_tr,\n",
    "                dataset_te = dataset_te,\n",
    "                sampler_cls=sampler_cls,\n",
    "                ratio=RATIO,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                clip=CLIP,\n",
    "                num_clusters=NUM_CLUSTERS,\n",
    "                eqsize=EQSIZE,\n",
    "                min_purity=MIN_PURITY,\n",
    "                load_clusters=LOAD_CLUSTERS,\n",
    "                save_clusters=SAVE_CLUSTERS,\n",
    "            )\n",
    "            experiment.run(\"../experiments\", RUN_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
