{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Example utilising hugging-face datasets and torchvision models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets & Dataloaders (cifar10 & resnet50 example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "cifar10 = load_dataset('cifar10')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "\n",
    "valid_size = int(0.2 * len(train_dataset))\n",
    "train_dataset, valid_dataset = random_split(train_dataset, [len(train_dataset) - valid_size, valid_size])\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare, train & test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from kiss.utils.configs import CONFIGS\n",
    "\n",
    "model = resnet50(num_classes=10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "device = CONFIGS.torch.device\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 625/625 [01:37<00:00,  6.42 batch/s, loss=1.9096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved from 0.00% to 33.56%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 625/625 [01:36<00:00,  6.45 batch/s, loss=1.7142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved from 33.56% to 43.85%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 625/625 [01:36<00:00,  6.48 batch/s, loss=1.5894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved from 43.85% to 44.18%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 625/625 [01:35<00:00,  6.51 batch/s, loss=1.5328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved from 44.18% to 51.80%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 625/625 [01:35<00:00,  6.51 batch/s, loss=1.3929]\n",
      "Epoch 6/10: 100%|██████████| 625/625 [01:36<00:00,  6.49 batch/s, loss=1.5160]\n",
      "Epoch 7/10: 100%|██████████| 625/625 [01:35<00:00,  6.51 batch/s, loss=1.3796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved from 51.80% to 57.46%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 625/625 [01:35<00:00,  6.54 batch/s, loss=1.4863]\n",
      "Epoch 9/10: 100%|██████████| 625/625 [01:35<00:00,  6.52 batch/s, loss=1.2527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved from 57.46% to 57.54%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 625/625 [01:36<00:00,  6.51 batch/s, loss=1.1694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mBest valid accuracy improved from 57.54% to 60.42%. Saving checkpoint...\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from kiss.utils.strings import Format\n",
    "\n",
    "num_epochs = 10\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\" batch\") as pbar:\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(loss=f\"{running_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    if accuracy > best_valid_acc:\n",
    "        with Format(Format.BOLD, Format.CYAN):\n",
    "            print(f\"Best valid accuracy improved from {best_valid_acc * 100:.2f}% to {accuracy * 100:.2f}%. Saving checkpoint...\")\n",
    "        best_valid_acc = accuracy\n",
    "        torch.save(model.state_dict(), \"../checkpoints/resnet50_prototype.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:28<00:00,  5.59 batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = resnet50(num_classes=10)\n",
    "model.load_state_dict(torch.load(\"../checkpoints/resnet50_prototype.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_loader), desc=\"Testing\", unit=\" batch\") as pbar:\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
